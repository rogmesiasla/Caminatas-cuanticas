
\section{Caminatas aleatorias clásicas}\label{CaminatasClasicas}
El espacio de movimientos puede ser espacio euclídeo. La longitud de los pasos es siempre la misma, y un paso se da cada cierto intervalo de tiempo igual. Es posible hacer las cantidades tan pequeñas como se quiera y considerar tiempo y espacio continuos.\\
Estudiaremos la posición de una partícula tras seguir una caminata de esta naturaleza: con pasos de igual longitud sobre la línea infinita, y una moneda como evento aleatorio. Nos interesa conocer la posición de la partícula.
%Emergencia de la simetría rotacional.Ecuación de difusión. Polímeros y caminatas aleatorias. Invarianza de escala, y universalidad. 
\subsection{Caminata aleatoria clásica sobre una recta.}
Si las probabilidades de ir a derecha o izquierda son iguales a $1/2$, y la posición de inicio es $x_0=0$, 
\begin{equation}
\langle x\rangle=0,\quad \langle x_ix_j\rangle=l^2\delta_{i,j}
\end{equation}{}
Después de $t$ pasos, la varianza $\sigma^2=tl^2$:
\begin{equation}{}
\sigma^2=\Big \langle \big(\sum_i^t x_i \big)^2 \Big \rangle = \sum_{i,j}^t \langle x_i x_j \rangle = tl^2,
\end{equation}
El valor esperado de la posición crece como $\sqrt{N}$, $\sigma\sim \sqrt{N}$. Si pensamos en $t$ como el tiempo,\\
Veamos cómo emerge el límite continuo:
\begin{equation}
    \langle\Delta y^i\rangle=\int d^D \Delta y [\Delta y p(\Delta \Vec{y})]=0,
\end{equation}{}
\begin{equation}
    \langle\Delta y^i\Delta y^j\rangle=\int d^D \Delta y [\Delta y^i\Delta y^jp(\Delta \Vec{y})]=\langle(\Delta y)^2\rangle\frac{\delta_{i,j}}{D}
\end{equation}{}
\begin{equation}
P_N(\Vec{x})=\int d^D \Delta y P_{N-1}(\Vec{x}-\Delta \Vec{y})p(\Delta \Vec{y})    
\end{equation}{}
\begin{equation}
    \frac{\partial\rho}{\partial t}=K\nabla^2\rho
    \end{equation}{}
que es la ecuación de difusión, cuya solución es una distribución gaussiana: $\rho(x,t)=\frac{e^{-x^2/4Kt}}{(4\pi Kt)^{D/2}}$, igual que el caso discreto.
%Esta ecuación macroscópica es un comportamiento emergente de las caminatas aleatorias. Otra característica emergente de estas caminatas es que en tiempos muy grandes su escala es invariante, que corresponde a un \textit{fractal}.

\subsection{Cadenas de Markov}
Un proceso estocástico en un espacio de estados discreto $X$, de tamaño $n=|X|$, es una cadena de Markov. Se describe por una \textit{matriz estocástica} $P$, en la que $p_{ab}\in [0,1]$ es la probabilidad de transición de $a$ a $b$, y para todo $a$:
\begin{equation}
    \sum_{b\in X}p_{ab}=1
\end{equation}
Toda cadena de Markov tiene un \textit{grafo dirigido subyacente} con $n$ vértices etiquetados con los nombres de $X$ y arcos dirigidos etiquetados con las probabilidades no nulas $p_{xy}$. La distribución de probabilidad sobre los vértices se representa por un vector fila $\Vec{u}$ con elementos reales no negativos que suman $1$. $\vec{u}$ se transforma con una aplicación de $P$ según $\vec{u}P=\Vec{v}$. Cuando $\vec{\pi}P=\vec{\pi}$, llamamos \textit{distribución estacionaria} a $\vec{\pi}$.\\

\noindent Una cadena de Markov es:
\begin{itemize}
    \item \textit{irreducible}, cuando cualquier vértice del grafo subyacente puede ser alcanzarse en un número de pasos finito
    \item \textit{aperiódica} 
    \item \textit{ergódica} si es irreducible y aperiódica.
\end{itemize}
Falta \textit{reversible}\\
\textbf{Teorema de Perron-Froebenious}: Sea $P$ una matriz estocástica. Entonces:
\begin{itemize}
    \item todos los autovalores de $P$ son a lo más $1$ en valor absoluto y $1$ es un autovalor de $P$;
    \item si $P$ es irreducible, entonces el 1-autovector es único y estrictamente positivo (esto es, es de la forma $c\vec{\pi}$, donde $c\neq 0$ y $\vec{\pi}$ es una distribución no nula en todas las entradas);
    \item si además de ser irreducible, $P$ es aperiódica, es decir, es ergódica, los demás autovalores de $P$ son estrictamente menores que $1$ en valor absoluto.
\end{itemize}

\subsection{Procesos de Markov\label{ProcesosMarkov}}
La distribución sobre la gráfica $\Gamma(V,E)$ es $\Vec{p}(t)=(p_1(t),\dots,p_{|V|})$. $p_i(t)$ corresponde a la probabilidad de estar en el vértice $i$. Un paso (o actualización) se da de acuerdo a la \textit{matriz adyacente} $(M)_{i,j}$ que tiene entradas cero sólo para las direcciones que no tienen conexión:

\begin{equation}
    \dfrac{d\Vec{p}(t)}{dt}=M\Vec{p}(t)
\end{equation}{}
Por ejemplo la matriz para el $N$-ciclo $M_N$ transforma un estado incial $\Vec{p}^0=(1,0,\dots,0)$ en $\Vec{p}^1=(0,\frac{1}{2},0,\dots,\frac{1}{2})$, $\Vec{p}^2=(\frac{1}{2},0,\frac{1}{4},\dots,0,\frac{1}{4},0)$, $\Vec{p}^3=(0,\frac{3}{8},0,\dots,0,\frac{1}{8},0,\frac{3}{8})$, etc.

\begin{equation*}
    M_N=\dfrac{1}{2}
    \begin{pmatrix}
    0& 1& 0& \cdots& 0 &1 \\
    1& 0& 1& 0& \cdots& 0\\
    0& 1& 0& 1& \cdots& 0\\
    &\vdots & &\ddots & & \\
    0& \cdots & 1 &0 &1 &0 \\
    0& \cdots&0 &1 &0 &1 \\
    1& 0& \cdots&0 &1 &0
    \end{pmatrix}{}
\end{equation*}{}
El movimiento browninano es el ejemplo más relevante de un proceso aleatorio en física.

\subsection{\textit{Mixing time} y \textit{hitting time}}

Las caminatas clásicas sobre gráficas convergen siempre hacia una distribución límite $\Vec{\pi}$. El \textit{mixing time} $M_\epsilon$ es una manera posible de medir la tasa de convergencia de una distribución y se define como
\begin{equation*}
    M_\epsilon=\text{min}\left\{T|\forall t \geq T,\Vec{p}^0:||\Vec{p}^{t}-\Vec{\pi}||\leq\epsilon\right\}
\end{equation*}{}
donde la distancia entre dos distribuciones $\Vec{p}$, $\Vec{q}$:
\begin{equation}
    ||\Vec{p}-\Vec{q}||=\sum_i|\Vec{p}_i-\Vec{q}_i|
\end{equation}{}
Resulta que $M_\epsilon$ tiene los siguientes valores límites, que contienen los primeros dos autovalores de la matriz de transiciones $M$, $\lambda_1=1$ y $\lambda_2$. Se mostrará cómo en el caso cuántico $M_\epsilon$ depende de \textit{todos} los autovalores de la evolución unitaria.
\begin{equation*}{}
\dfrac{\lambda_2}{(1-\lambda_2)\log2\epsilon}\leq M_\epsilon\leq\dfrac{1}{(1-\lambda_2)}(\max_i\log\Vec{\pi}_i^{-1}+\log\epsilon^{-1})
\end{equation*}
\textit{Hitting time} es el número de pasos que le toma a una caminata ir desde un vértice $i$ hasta uno $j$ dentro de la gráfica. Es usual el uso del promedio de este tiempo.\\

Dos ejemplos que revisaremos para el caso cuántico son:\\

\textbf{Círculo:} En el $N$-círculo, $M_\epsilon\sim N^2$, y también lo es el hitting time promedio $T\sim N^2$.\\

\textbf{Hipercubo:} En el $d-$hipercubo $M_\epsilon\sim d\log d\log (1/\epsilon)$, y 
$T\sim 2^d$. Este último es mejorado exponencialmente por el caso cuántico.

\section{Caminata cuántica de tiempo continuo}
Childs definió las caminatas cuánticas de tiempo continuo en analogía con los procesos de Markov \cite{childs2002example}. Al identificar el hamiltoniano $\hat{H}$ de la evolución cuántica con la matriz adyacente en un grafo, la ecuación de Schrödinger en una base finita y la ecuación de un proceso de markov son similares:
\begin{equation}
\frac{dp_a(t)}{dt}=\sum_bM_{a,b}p_b(t),\qquad \qquad    
-i\frac{d}{dt}\braket{a|\psi(t)}=\sum_b\braket{a|\hat{H}|b}\braket{b|\psi(t)}
\end{equation}{}
\begin{equation}
    \bra{a}\hat{H}\ket{b}=H_{a,b}=
    \left\{
    \begin{array}{ll}
    \gamma  &  a\neq b \;\; (a,b)\in \Gamma \\
    0   & a\neq b  \;\; (a,b) \not\in \Gamma  \\
    -d(a)\gamma & a=b.     
    \end{array}
    \right.
\end{equation}{}

La transición es posible \textit{todos} los tiempos y no solamente en tiempos discretos. En un tiempo muy pequeño $\epsilon$, la probabilidad de transición para la partícula es $\gamma \epsilon\,\,\,(\epsilon\xrightarrow{}0)$, así que $\gamma$ es la probabilidad de transición por unidad de tiempo. 
\begin{equation*}
    \bra{v}\hat{H}\ket{v'}=
    \left\{
    \begin{array}{cll}
    \gamma  &  v\neq v' & (v,w)\in G  \\
    0 & \text{otherwise}  & \end{array}
    \right.
\end{equation*}{}
$\hat{H}$ es hermítica, así que la probabilidad se conserva $\sum_v |\braket{v|\psi(t)}|^2=1$.